{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5f2a46-e7c1-4564-8be7-2d7f23138f74",
   "metadata": {},
   "source": [
    "## 1. subsequent_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47974f7a-4594-43df-90d6-9c254be6df8a",
   "metadata": {},
   "source": [
    "> 生成掩码矩阵，用于遮盖数据，返回的是布尔值的torch.tensor矩阵，其中 true 表示在解码时能看到的数据，False表示遮蔽，可以看到随着解码的进行数据也逐渐增加。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e90a284-e570-4490-9090-21334846983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74cdf5c8-45bf-467a-a21f-5018fee44866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f4a8856-9606-4281-aea4-74bb1c0612fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ True, False, False, False, False],\n",
      "         [ True,  True, False, False, False],\n",
      "         [ True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True]]]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "ans = subsequent_mask(5)\n",
    "print(ans, type(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf871b7-df96-4f34-a740-521f36863ef5",
   "metadata": {},
   "source": [
    "## 2. Batch 类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f1317b7-64bd-4736-b29a-8edbd612b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1c581737-a0d9-4442-aa3e-f89d8ff0db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        # 输入数据的 mask ，即数值是否等于 pad 构成的二值矩阵\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            # 丢掉目标数据的最后一个值\n",
    "            self.trg = trg[:, :-1]\n",
    "            # 丢掉目标数据的第一个值\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            # 根据给定的 pad 来制作目标值的 mask\n",
    "            self.trg_mask = self.make_std_mask(self.trg, pad)\n",
    "            # ntokens 即为目标数据中除去 pad 还有多少数字\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        # 将目标数据中等于 pad 的数值遮盖\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        # 进一步进行目标值的上三角遮盖，维度为最后一个维度，即数据维度\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        # 最终返回的 shape 为 batchsize * tgt * tgt，即针对每个目标值的一个上三角遮盖矩阵\n",
    "        # 另外还遮盖了其中数值等于 pad 的部分\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426bd4f3-903e-47f2-8919-af41141c6c9d",
   "metadata": {},
   "source": [
    "### unsqueeze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d3ce21-b929-4469-830f-50cc64f74661",
   "metadata": {},
   "source": [
    "> unsqueeze 作用为在指定维度进行升维，举例来说如原始为两行的数据，进行升维即将此数据看成另一个维度上仅有一列，即变为两行一列的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcf73f45-efd5-48b0-9358-f5e0858f76b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]]]) torch.Size([1, 2, 3])\n",
      "tensor([[[[1., 1., 1.]],\n",
      "\n",
      "         [[1., 1., 1.]]]]) torch.Size([1, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((1,2,3))\n",
    "print(a, a.shape)\n",
    "b = a.unsqueeze(-2)\n",
    "print(b, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "902915a0-73f4-4b1b-82fb-4d36e2649f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True]],\n",
       "\n",
       "         [[True, True, True]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = 0\n",
    "c = (a != pad).unsqueeze(-2)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62b81d1-7dd7-426c-8da9-ac896a193b5c",
   "metadata": {},
   "source": [
    "### torch 索引与切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce77caea-7677-4791-9178-53e91eb52101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6570,  0.7658,  0.0468,  1.2239],\n",
       "        [-0.6662, -0.3183,  1.6796,  0.5557],\n",
       "        [ 1.0227, -1.0913, -0.0940,  0.4967]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = torch.randn(3,4)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93f40af-7f5b-4cbd-bb91-07ed665f7056",
   "metadata": {},
   "source": [
    "> 冒号表示对维度内的切片操作，逗号表示对维度的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "baf15520-cc9c-476d-a1c9-40bec81ab094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6570, -0.6662,  1.0227])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:, 0]  # 所有行的第 0 列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2de38a07-8edb-4e56-a4c5-675a1fe04a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6662,  1.0227])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1:, 0]  # 第一行开始的第 0 列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35687406-2ec4-427e-b548-45215ccd113e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6570, -0.6662])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:-1, 0]  # 不要最后一行的第一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "199fb91b-7dba-43c3-9204-4ffd5b7af89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6570)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0, 0]  # 第 0 行第 0 列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb4b25ac-24b8-4c53-ab25-ddbde2169e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6570,  0.7658,  0.0468],\n",
       "        [-0.6662, -0.3183,  1.6796],\n",
       "        [ 1.0227, -1.0913, -0.0940]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:, :-1]  # 不要第二个维度的最后一个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a6fd4ba-23c3-469b-9643-117ef98c4690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7658,  0.0468,  1.2239],\n",
       "        [-0.3183,  1.6796,  0.5557],\n",
       "        [-1.0913, -0.0940,  0.4967]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:, 1:]  # 不要第二个维度的第一个值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4929a3b-8e0c-4ca0-9bbe-d1a2016d6011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 0, 2],\n",
      "         [0, 3, 4]],\n",
      "\n",
      "        [[5, 0, 5],\n",
      "         [7, 8, 0]]])\n",
      "tensor([[[[ True, False,  True]],\n",
      "\n",
      "         [[False,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False,  True]],\n",
      "\n",
      "         [[ True,  True, False]]]])\n"
     ]
    }
   ],
   "source": [
    "e = torch.tensor([[[1,0,2],[0,3,4]], [[5,0,5], [7,8,0]]])\n",
    "f = (e != 0).unsqueeze(-2)\n",
    "print(e)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fc1e78b3-9416-465c-8784-7a1148f156a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ True, False, False],\n",
      "         [ True,  True, False],\n",
      "         [ True,  True,  True]]])\n",
      "tensor([[[[ True, False, False],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[False, False, False],\n",
      "          [False,  True, False],\n",
      "          [False,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True, False, False],\n",
      "          [ True, False, False],\n",
      "          [ True, False,  True]],\n",
      "\n",
      "         [[ True, False, False],\n",
      "          [ True,  True, False],\n",
      "          [ True,  True, False]]]])\n"
     ]
    }
   ],
   "source": [
    "g = subsequent_mask(3)\n",
    "print(g)\n",
    "print(f & g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca47b96-c0aa-4480-b2ca-1c61aba05a8e",
   "metadata": {},
   "source": [
    "## NoamOpt类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a4af6-1918-48d3-a3f4-1ad87b296e29",
   "metadata": {},
   "source": [
    "> 优化器类，更新模型参数及调整学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d3c4f84c-d7fd-4f1b-9726-c3861886c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9900c7d8-8ccd-457e-a1f4-f5a4b91091fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "    \n",
    "    \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(\n",
    "            model_size = model.src_embed[0].d_model,  # 词向量特征维度\n",
    "            factor = 2, \n",
    "            warmup = 4000, # 超参\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9),  # 优化器 Adam\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c43180f-88c6-409d-8a3b-65662d5e9acd",
   "metadata": {},
   "source": [
    "## LabelSmoothing类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e2095-e2cb-4f02-a9c3-0228611a1e54",
   "metadata": {},
   "source": [
    "> 标签平滑，防止过拟合，感觉没什么必要用，这里的作用即为平滑 tgt 数据之后再计算 loss，实际中感觉可能直接实例化一个 loss 对象就足够。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7186e5a-da5b-40bd-8e83-c0aa74cc9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78fbbe1-84cf-44b5-87d6-bbd05c7de974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        # self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.criterion = nn.KLDivLoss(reduction='sum')  # 修改于 2022.12.2\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9507abbc-a64b-4208-a22d-a41139474878",
   "metadata": {},
   "source": [
    "### nonzero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c4e15-23c8-4357-8c66-d81103d671c5",
   "metadata": {},
   "source": [
    "> 返回 tensor 中满足条件的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3358df27-313c-4cea-90f7-3a6dde1d84e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3], [3,2,1]])\n",
    "b = torch.nonzero(a <= 2)\n",
    "b.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "250ad0f7-00d3-43f4-968c-e6d932f1e592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6543, dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,1,2], dtype = torch.float64)\n",
    "target = torch.tensor([1,1,1], dtype = torch.float64)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "loss(x, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ea645-0b54-48bf-b3f1-8feb744eafb9",
   "metadata": {},
   "source": [
    "## SimpleLossCompute类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773ee1f-e0d5-4896-81a7-10b160e585cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        # return loss.data[0] * norm\n",
    "        return loss.data.item() * norm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8beacac-743b-473d-9793-837f75e546fe",
   "metadata": {},
   "source": [
    "## run_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b0076ade-7e83-433e-8b72-15330aedc54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ddc359c8-590a-4cd1-9355-daab385021a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, \n",
    "                            batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        # 每 50 条数据打印一波\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28154954-21a1-4058-8b8e-f1948fe18c14",
   "metadata": {},
   "source": [
    "## greedy_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e4543-65a9-4813-905e-c57aec071de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406dd94-2f7a-4e14-bf31-37e13f7c27f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc76ef5-e702-4deb-b0f3-42062fa231f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9254e6b3-8a2a-4ba6-996c-5b98dd029606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46412dcc-4e7c-4d02-9765-7a9b6c516da6",
   "metadata": {},
   "source": [
    "# 总结："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af679f-db8b-4789-998a-2fb23aefc014",
   "metadata": {},
   "source": [
    "> 总体来说这个包的功能就是定义了一些训练用的函数，如优化器，dataloader等；具体情境中还需要自己重新定义功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7a8626f-7b6d-401b-8d45-75f17a048904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b11357c2-c0d8-476c-a65f-df9379d7cfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6576, -1.0978,  1.6274, -0.8762,  0.0320,  0.9722]],\n",
       "\n",
       "        [[ 0.3052, -1.4259,  0.9165, -1.3449,  0.6635,  0.8857]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Transformer(d_model = 6, nhead = 2, dim_feedforward = 20, batch_first = True)\n",
    "x = torch.randn(2,3,6)\n",
    "out = torch.randn(2,1,6)\n",
    "net(x, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cd7394e-5202-475b-b072-5da309a0a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "017f11b3-8072-43ec-b93a-2760455b8479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 9, 8, 2, 9, 3, 3, 5, 4, 1],\n",
       "        [8, 8, 2, 9, 7, 2, 4, 2, 2, 3],\n",
       "        [7, 9, 4, 4, 3, 7, 3, 9, 1, 5]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(1, 10, (3, 10))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d02ccd53-c6dd-4778-88c6-d4058d856188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3096,  0.4286,  0.5982, -0.9742],\n",
       "         [ 0.9723, -1.3930,  1.2595,  0.7597],\n",
       "         [ 1.3096,  0.4286,  0.5982, -0.9742],\n",
       "         [ 0.2701, -1.0025,  2.3486, -0.6930],\n",
       "         [ 0.9723, -1.3930,  1.2595,  0.7597],\n",
       "         [-0.6460, -0.2801,  0.1728,  0.7232],\n",
       "         [-0.6460, -0.2801,  0.1728,  0.7232],\n",
       "         [-1.4891,  1.3442,  0.0901,  0.8951],\n",
       "         [ 0.3977, -1.6202, -0.0646, -0.6646],\n",
       "         [-0.9903, -0.9874, -0.6288,  0.3669]],\n",
       "\n",
       "        [[ 1.3096,  0.4286,  0.5982, -0.9742],\n",
       "         [ 1.3096,  0.4286,  0.5982, -0.9742],\n",
       "         [ 0.2701, -1.0025,  2.3486, -0.6930],\n",
       "         [ 0.9723, -1.3930,  1.2595,  0.7597],\n",
       "         [-0.2337,  0.8694,  1.4526, -0.4023],\n",
       "         [ 0.2701, -1.0025,  2.3486, -0.6930],\n",
       "         [ 0.3977, -1.6202, -0.0646, -0.6646],\n",
       "         [ 0.2701, -1.0025,  2.3486, -0.6930],\n",
       "         [ 0.2701, -1.0025,  2.3486, -0.6930],\n",
       "         [-0.6460, -0.2801,  0.1728,  0.7232]],\n",
       "\n",
       "        [[-0.2337,  0.8694,  1.4526, -0.4023],\n",
       "         [ 0.9723, -1.3930,  1.2595,  0.7597],\n",
       "         [ 0.3977, -1.6202, -0.0646, -0.6646],\n",
       "         [ 0.3977, -1.6202, -0.0646, -0.6646],\n",
       "         [-0.6460, -0.2801,  0.1728,  0.7232],\n",
       "         [-0.2337,  0.8694,  1.4526, -0.4023],\n",
       "         [-0.6460, -0.2801,  0.1728,  0.7232],\n",
       "         [ 0.9723, -1.3930,  1.2595,  0.7597],\n",
       "         [-0.9903, -0.9874, -0.6288,  0.3669],\n",
       "         [-1.4891,  1.3442,  0.0901,  0.8951]]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embd = torch.nn.Embedding(10, 4)\n",
    "embd(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a51f877-d9b9-42de-9a09-4e740c709b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 3, 3, 2, 6, 3, 9, 1, 9, 2],\n",
       "        [2, 6, 1, 5, 7, 5, 4, 3, 9, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(1, 10, (2, 10))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5626d213-37e2-4bda-852b-8f55cdf53406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 3., 3., 2., 6., 3., 9., 1., 9., 2.],\n",
       "        [2., 6., 1., 5., 7., 5., 4., 3., 9., 2.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.clone().detach()\n",
    "z = y.to(torch.float64)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c779874f-0485-410a-a2dc-ac5db45c6164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e0c51d-282a-40b3-8196-e7c01ba9c8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 3., 3., 2., 6., 3., 9., 1., 9., 2.],\n",
       "        [2., 6., 1., 5., 7., 5., 4., 3., 9., 2.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.clone(z)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fafaede4-bb53-47e0-807a-fa51585678f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "from torch.nn.modules import Transformer\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab, dim) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.embd = nn.Embedding(vocab, dim)\n",
    "        self.transformer = Transformer(\n",
    "            d_model=dim, \n",
    "            nhead=2, \n",
    "            num_encoder_layers=1, \n",
    "            num_decoder_layers=1, \n",
    "            dim_feedforward=16, \n",
    "            batch_first=True\n",
    "            )\n",
    "        self.proj = nn.Linear(dim, 1)\n",
    "\n",
    "    def forward(self, x, y, tgt_mask):\n",
    "        x = self.embd(x)\n",
    "        y = self.embd(y)\n",
    "        x = self.transformer(x, y, tgt_mask = tgt_mask)\n",
    "        x = self.proj(x)\n",
    "        # print(x)\n",
    "        return torch.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca7363dd-98ee-4452-840d-05ff43640a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embd): Embedding(10, 4)\n",
       "  (transformer): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=4, out_features=16, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=4, out_features=4, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=4, out_features=16, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (norm1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (proj): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net(10, 4)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36cbccb0-c317-4b29-880f-c87050970329",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Transformer(num_encoder_layers=1, num_decoder_layers=1)\n",
    "# print(net, id(net))\n",
    "newnet = nn.Sequential(*list(net.children()))\n",
    "# print(newnet, id(newnet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3257282-acda-4b1b-a86c-4420b8e701e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.randint(1, 10, (2, 5))\n",
    "res = torch.ones(1, 1).fill_(0).type_as(src.data)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5962cc14-4dd6-402f-9175-7aadfa1ed658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1]])\n",
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "res = torch.cat([res, torch.ones(1, 1).type_as(src.data).fill_(1)], dim=1)\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3a3b61c4-feaf-4e1b-99e0-c479fd9614f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attn(query, key, value):\n",
    "    if key is value:\n",
    "        if query is key:\n",
    "            query = key = value = query.transpose(1, 0)\n",
    "        else:\n",
    "            query, key = [x.transpose(1, 0) for x in (query, key)]\n",
    "            value = key\n",
    "    else:\n",
    "        query, key, value = [x.transpose(1, 0) for x in (query, key, value)]\n",
    "    return query.shape, key.shape, value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f45c19af-18eb-4a47-ac30-db9b553a25b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 4]), torch.Size([10, 1, 4]), torch.Size([10, 1, 4]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attn = torch.nn.MultiheadAttention(embed_dim=4, num_heads=1)\n",
    "query = torch.randn(1, 1, 4)\n",
    "key = value = torch.randn(1, 10, 4)\n",
    "attn(query, key, value)\n",
    "# query.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08885eac-2c98-4e05-9211-9e5a782c2731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea10207-8d5b-42dd-a1af-c3d58f4c6102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b8c780-81ee-4113-b587-c062d6efb62f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe10663-736d-472c-b44d-11987ed14aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d26cfb0-cf4e-4f66-bf74-cd29a5b91903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188124bc-bc94-4808-b39e-21c6c614f8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ebcb31-359d-4cd1-8b79-386ad90ce59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72aed9-4fe7-471d-96bd-8c7181d783dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041177fc-271a-4b51-ac9f-37bc27e0ea98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
