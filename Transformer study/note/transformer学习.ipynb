{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f855ab-15ff-4d26-b24b-32cb7cffd23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee667ff8-0366-461c-9535-4dad335ed9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254503e0-dc51-479c-b5bb-1038542b4c44",
   "metadata": {},
   "source": [
    "# 输入层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63a98a-3133-4604-9125-54c92487cd1f",
   "metadata": {},
   "source": [
    "## embedding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2a1db4-1ea2-4a1a-bd41-6fa60153177e",
   "metadata": {},
   "source": [
    "作用：将输入空间的一个值映射成特征空间中的高维向量，希望在高维空间捕捉词汇间的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3851b70d-db49-44c6-8bc8-d157ef8c8faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1120,  0.2073,  0.7566],\n",
       "        [-0.3458,  1.8638,  0.7209],\n",
       "        [-0.1936, -0.1341,  1.1532],\n",
       "        [-0.3584,  1.1800,  0.1187],\n",
       "        [ 0.1320,  0.5332,  0.3781]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "embd = nn.Embedding(10, 3)  # 输入空间10个元素，每个都映射成3维向量\n",
    "input = torch.tensor([1,2,3,4,5])\n",
    "embd(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6393bfb2-da74-4b72-8b67-d081988941cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0313,  1.5260, -0.8182],\n",
       "        [-0.7808, -0.3657,  0.2140],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 1.3338,  0.8547,  1.0599],\n",
       "        [ 0.1208, -0.5930,  0.7166]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embd = nn.Embedding(10, 3, padding_idx=3)  # 将指定元素映射成 0 \n",
    "input = torch.tensor([1,2,3,4,5])\n",
    "embd(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b51798-b451-4e76-ac0c-df2b3372da19",
   "metadata": {},
   "source": [
    "### embedding类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb1fa0de-4d06-4ec3-adf7-dfeb417177c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        # d_model: 词嵌入的维度\n",
    "        # vocab: 词表的大小\n",
    "        super(Embeddings, self).__init__()\n",
    "        # 定义Embdding层\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x为输入进模型的文本通过词汇映射后的数字张量\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd45fae3-626f-48b3-b62c-85d0f858eb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7681,  0.6057,  1.6045],\n",
       "         [ 0.0447,  1.5964,  2.6488]],\n",
       "\n",
       "        [[ 0.1470,  0.6834,  3.0567],\n",
       "         [-2.6747,  0.7002, -1.4043]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 3\n",
    "vocab = 10\n",
    "x = Variable(torch.LongTensor([[1,2], [3,4]]))\n",
    "emb = Embeddings(d_model, vocab)\n",
    "emb(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba03dcc-84bd-44e5-bf27-9ce43e4df8e0",
   "metadata": {},
   "source": [
    "## Position Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d548e-e383-4156-aea4-f94c6f4d9135",
   "metadata": {},
   "source": [
    "<a>https://zhuanlan.zhihu.com/p/106644634</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd1aada-6e24-45e7-af69-7b139d877700",
   "metadata": {},
   "source": [
    "dropout: 丢弃一部分值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1746936-9075-4ec4-953a-49dcc1a233ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6638f2a-50b7-4267-abe4-7f43020b6c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8570,  0.1192, -0.9470,  0.2433, -1.0871],\n",
      "        [-0.1387,  0.7731, -2.3681, -0.8907, -0.7810],\n",
      "        [-0.5403,  1.0688, -0.0794, -0.1415, -0.2017],\n",
      "        [ 0.2693,  0.0621, -0.1020, -0.6094, -1.0652]]) \n",
      " tensor([[0., 0., -0., 0., -0.],\n",
      "        [-0., 0., -0., -0., -0.],\n",
      "        [-0., 0., -0., -0., -0.],\n",
      "        [0., 0., -0., -0., -0.]])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Dropout(p=1)\n",
    "input = torch.randn(4, 5)\n",
    "print(input, \"\\n\", m(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fe6467-d589-4b5d-92a8-b569ad23ffea",
   "metadata": {},
   "source": [
    "unsquezze: 张量升维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f70130-5e60-42d2-9b8e-c2efa18193dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50a87294-abf3-4745-a8ce-6110a6a9acb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ecd13ab-0a0e-4a73-b298-d49e2690ed28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]]) torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "y = torch.unsqueeze(x, 0)\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a800de5f-e5a7-45b6-be2f-b015f0afdeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "z = torch.unsqueeze(x, 1)\n",
    "print(z, z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea91ef0-a21d-4b07-9680-790de64b9998",
   "metadata": {},
   "source": [
    "### Positional Encoding 类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ab223-95ca-40b6-be37-1bdfc5c3eba6",
   "metadata": {},
   "source": [
    "给定一个长度为n的输入序列，让t表示词在序列中的位置，$\\vec{p_t} \\in R^d$ 表示t位置对应的向量，d是向量的纬度。  \n",
    "$f:N \\rightarrow R^d$ 是生成位置向量 $\\vec{p_t}$ 的函数，定义如下：\n",
    "$$\\vec{p_t}^{(i)} = f(t)^{i} := \n",
    "\\begin{cases}\n",
    "sin(\\omega_k \\cdot t) & i = 2k \\\\\n",
    "cos(\\omega_k \\cdot t) & i = 2k + 1\n",
    "\\end{cases}\n",
    "$$\n",
    "其中，频率w_k 定义如下：\n",
    "$$\\omega_k = \\frac{1}{10000^{2k/d}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b8550bf-0098-4aa2-87b5-51230aa93bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import unsqueeze\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        # d_model 词嵌入的纬度\n",
    "        # dropout 置零比率\n",
    "        # max_len 句子最大长度\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        # 实例化 dropout\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # 初始化一个位置编码矩阵， 大小是 maxlen * d_model\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        # 初始化一个绝对位置矩阵 maxlen * 1\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "\n",
    "        # 定义一个变化矩阵div_term, 跳跃式的初始化\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "\n",
    "        # 将定义的变化矩阵进行奇数，偶数的分别赋值\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # 增维\n",
    "        pe = pe.unsqueeze(0)\n",
    "        \n",
    "        # 注册成bufer\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x 代表文本序列的词嵌入表示（即张量表示）\n",
    "        # 将 pe 截取到输入序列的长度\n",
    "        # print(x.shape, self.pe[:, :x.size(1)].shape, self.pe.shape)\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad = False)  # 不参与训练更新 \n",
    "        return self.dropout(x)  # 返回携带了位置编码并丢弃一部分值的结果\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaafa157-8228-4079-a4e8-771d2509d6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: tensor([[1, 2, 3],\n",
      "        [1, 3, 5]]) torch.Size([2, 3])\n",
      "emb: tensor([[[-0.3166, -1.3563, -1.5514, -3.4348],\n",
      "         [ 1.4588, -1.6432, -1.2367, -3.3309],\n",
      "         [ 0.5503,  0.2891,  0.7986, -0.1928]],\n",
      "\n",
      "        [[-0.3166, -1.3563, -1.5514, -3.4348],\n",
      "         [ 0.5503,  0.2891,  0.7986, -0.1928],\n",
      "         [-0.3156,  0.3774, -0.2601,  0.7235]]], grad_fn=<MulBackward0>) torch.Size([2, 3, 4])\n",
      "pe: tensor([[[-0.3518, -0.3959, -1.7237, -0.0000],\n",
      "         [ 2.5559, -1.2254, -1.3630, -2.5900],\n",
      "         [ 1.6217, -0.1412,  0.9095,  0.8966]],\n",
      "\n",
      "        [[-0.3518, -0.3959, -0.0000, -2.7053],\n",
      "         [ 1.5464,  0.9216,  0.8984,  0.8968],\n",
      "         [ 0.6597, -0.0430, -0.2668,  1.9147]]], grad_fn=<MulBackward0>) torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "d_model = 4  # 要是 2 的倍数\n",
    "vocab = 10\n",
    "dropout = 0.1\n",
    "maxlen = 60\n",
    "x = Variable(torch.LongTensor([[1,2,3], [1,3,5]]))\n",
    "emb = Embeddings(d_model, vocab)\n",
    "embx = emb(x)\n",
    "pe = PositionalEncoding(d_model, dropout, maxlen)\n",
    "pex = pe(embx)\n",
    "print(\"origin:\", x, x.shape)\n",
    "print(\"emb:\", embx, embx.shape)\n",
    "print(\"pe:\", pex, pex.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88054a6f-b4ea-463c-9717-471107462269",
   "metadata": {},
   "source": [
    "### PE可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31aeb5c-ec47-4dd3-a7e3-647221f5027f",
   "metadata": {},
   "source": [
    "# 编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9652b56-7515-4382-8851-f1bf1f92108e",
   "metadata": {},
   "source": [
    "## 掩码张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288265b6-4f79-48c1-903c-ab4f4f204896",
   "metadata": {},
   "source": [
    "掩盖住输入的一部分信息使得模型不违反因果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30e01678-78a3-468b-b817-f49d03cb2d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2, 3],\n",
       "       [0, 0, 6],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "m = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "np.triu(m, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660929bf-11f2-4152-a474-0fb0bca21804",
   "metadata": {},
   "source": [
    "### 构建掩码张量的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7097941-e49b-4ca1-a61c-1451c0eb5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    # size 代表掩码张量的后两个纬度，形成一个方阵\n",
    "    attn_shape = (1, size, size)\n",
    "    \n",
    "    # 构建上三角矩阵\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k = 1).astype(\"uint8\")  # 节省空间\n",
    "    return torch.from_numpy(1 - subsequent_mask)  # 反转返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16713bf4-78f9-463d-8b98-2d1015a32308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 5\n",
    "subsequent_mask(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fd8ab5-94b8-4b75-8a93-9ddc6d0c2548",
   "metadata": {},
   "source": [
    "其中 0 代表被遮掩 1 代表没有被遮掩，可以看到随着处理的词汇增加，可以利用的词汇也增加，不会出现因果问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "849a8bea-d7e7-49dd-bdb9-14d199eddfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.imshow(subsequent_mask(20)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee353c92-3795-4fa6-9286-c4e23477a017",
   "metadata": {},
   "source": [
    "## 注意力机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff073e5-bffa-4d1f-b745-6bd5c1562099",
   "metadata": {},
   "source": [
    "Q K V 的比喻解释：  \n",
    "假设现在需要对一段文本进行描述，为方便这个过程的进行，给出一些关键词，则文本可以看作query， 提示的关键词可看作key，最终需要我们得出的文本的描述信息被称为value，最初我们只知道这些关键词，即此时value和key基本相同，但随着我们对问题的深入理解，value开始逐渐变化，最终完成任务，得到文本的描述，这个过程就是注意力作用的过程。\n",
    "\n",
    "一般情况下最初key与value相同但与query不同，即一般的注意力输入形式。但有一种特殊的注意力机制，此处query = key = value，即自注意力机制，比喻来说就是需要从给定的文本中抽取关键词来描述它，相当于对文本自身做了一次特征提取。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5373b9d-0c96-49b6-be09-559b2a11de79",
   "metadata": {},
   "source": [
    "$$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef30bb9-e157-4752-97ba-b4ed02df6df6",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=./imgs/attention.png width=30% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44657d77-117f-471e-8b59-19460a4aeb59",
   "metadata": {},
   "source": [
    "### 1. mask fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1d3d73a-5306-4f20-bcd4-bfaff564f364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2285,  1.0086, -0.8663, -0.1387, -0.2359],\n",
       "        [ 1.1106, -0.0918, -0.6523, -0.8730, -0.0174],\n",
       "        [-0.2812, -0.5392, -0.9327, -0.1785,  0.6068],\n",
       "        [ 1.7927, -0.1893, -2.2222, -0.9944, -2.1909],\n",
       "        [ 0.3817,  1.1343, -0.1169, -0.2870, -0.3145]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.randn(5, 5))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c5f8da8-3caa-4873-b51f-6eca24e76781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = Variable(torch.zeros(5, 5))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f1cdd9-8a7d-4ac8-a3e6-ce149e081e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09],\n",
       "        [-1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09, -1.0000e+09]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.masked_fill(mask == 0, -1e9)  # 0 的位置都替换成很小的数，达到mask的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac63614-9f5d-4ae9-ab4c-7c7762fda371",
   "metadata": {},
   "source": [
    "### 2. attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a27a3f64-42cb-4099-b547-2903a522afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def attention(query, key, value, mask = None, dropout = None):\n",
    "    # 此处dropout为一个dropout层对象\n",
    "    \n",
    "    d_k = query.size(-1)  # query的最后一个纬度，即特征向量的纬度\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)  # 计算attention\n",
    "    # print(scores.size())\n",
    "    if mask is not None: scores = scores.masked_fill(mask == 0, -1e9)  # 掩码\n",
    "    p_attn = F.softmax(scores, dim = -1)  # 对最后一格纬度做softmax，即得到attention在特征空间各个分量的分数\n",
    "    if dropout is not None: p_attn = dropout(p_attn)\n",
    "    \n",
    "    # 完成attention的计算\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3161f8ec-c50a-4b81-a393-2f936b05fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: tensor([[1, 2],\n",
      "        [1, 5]]) torch.Size([2, 2])\n",
      "emb: tensor([[[ 1.7049,  2.7717],\n",
      "         [-1.7638,  1.7419]],\n",
      "\n",
      "        [[ 1.7049,  2.7717],\n",
      "         [-1.9604,  0.2723]]], grad_fn=<MulBackward0>) torch.Size([2, 2, 2])\n",
      "pe: tensor([[[1.8943, 4.1908],\n",
      "         [-0.0000, 2.5358]],\n",
      "\n",
      "        [[1.8943, 0.0000],\n",
      "         [-0.0000, 0.9029]]], grad_fn=<MulBackward0>) torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "d_model = 2  # 要是 2 的倍数\n",
    "vocab = 10\n",
    "dropout = 0.1\n",
    "maxlen = 60\n",
    "x = Variable(torch.LongTensor([[1,2], [1,5]]))\n",
    "emb = Embeddings(d_model, vocab)\n",
    "embx = emb(x)\n",
    "pe = PositionalEncoding(d_model, dropout, maxlen)\n",
    "pex = pe(embx)\n",
    "print(\"origin:\", x, x.shape)\n",
    "print(\"emb:\", embx, embx.shape)\n",
    "print(\"pe:\", pex, pex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8007ce52-ce10-43b5-b77f-35d2b07b90fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9472, 3.3633],\n",
       "          [0.9472, 3.3633]],\n",
       " \n",
       "         [[0.9472, 0.4515],\n",
       "          [0.9472, 0.4515]]], grad_fn=<UnsafeViewBackward0>),\n",
       " tensor([[[0.5000, 0.5000],\n",
       "          [0.5000, 0.5000]],\n",
       " \n",
       "         [[0.5000, 0.5000],\n",
       "          [0.5000, 0.5000]]], grad_fn=<SoftmaxBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = key = value = pex  # 文本嵌入位置编码之后的输入\n",
    "mask = Variable(torch.zeros((2,2,2)))\n",
    "attention(query, key, value,mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d028d4-9e4c-440a-bdf3-4f50f94a0b26",
   "metadata": {},
   "source": [
    "transpose 的语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "589f11f1-2721-4d1d-a048-861d63434c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3], [1,2,3]], [[3,4,5], [3,4,5]]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79bba20c-3f4f-43a7-b308-7858030be502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1],\n",
       "         [2, 2],\n",
       "         [3, 3]],\n",
       "\n",
       "        [[3, 3],\n",
       "         [4, 4],\n",
       "         [5, 5]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.transpose(-2, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d152487-0b6f-4e5b-b3ed-2bba3bb2e515",
   "metadata": {},
   "source": [
    "第一个通道都是channel，即有多少个形状一样的矩阵，对后两个维度转置即为对高维矩阵中的每一个二维矩阵进行转置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36091b72-a75d-464d-ac93-821ae19bff8f",
   "metadata": {},
   "source": [
    "### 3. 多头注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a7436-3b7b-4b79-b3ad-ba64471f2a4a",
   "metadata": {},
   "source": [
    "利用多个注意力机制使得每个结构都注意到原始特征的不同部分，均衡同一种注意力机制可能产生的偏差。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f435516a-5e04-4b39-815c-658c365fd437",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=./imgs/muti-attention.png width=30% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c82354-9a97-4d9a-bb6a-3d2c4ab70752",
   "metadata": {},
   "source": [
    "这里V K Q在计算attention之前都进行了全连接层的操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b535a-13f6-4349-a40d-8f076a95674c",
   "metadata": {},
   "source": [
    "#### torch.view() 改变矩阵形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9748aa76-4b6b-448c-a620-8ca351f456bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((4, 4))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e096d07-e564-42d7-83c3-cb13d4237144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8144,  0.2960, -1.4826, -0.2169,  1.0038, -1.2349,  0.9982,  1.8104,\n",
       "        -0.7132, -1.3654, -0.2447,  0.2305,  0.0745,  0.7838, -0.9695, -0.8112])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "205ee9cb-ef44-4c14-98c4-5607bd413dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8144,  0.2960, -1.4826, -0.2169],\n",
       "        [ 1.0038, -1.2349,  0.9982,  1.8104],\n",
       "        [-0.7132, -1.3654, -0.2447,  0.2305],\n",
       "        [ 0.0745,  0.7838, -0.9695, -0.8112]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1, 4)  # -1 自动匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4423ac-a10d-49d0-9891-9b0613dbe8b7",
   "metadata": {},
   "source": [
    "#### transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41a7dd71-9379-42b0-ba53-0d06465d5250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1405,  0.0080, -0.4701,  1.6622],\n",
       "          [-1.0113, -1.1622,  0.3613,  0.8428],\n",
       "          [-1.5466, -1.7818, -0.2423, -0.8024]],\n",
       "\n",
       "         [[ 1.8207,  0.5783,  0.3131,  0.3011],\n",
       "          [-0.9022,  0.5600,  0.8024,  1.3328],\n",
       "          [ 1.1283,  1.4759,  0.2779,  0.4628]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 2, 3, 4)\n",
    "x.shape\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dbfebad-1062-4f2e-aafd-86600db57714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2, 4])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.transpose(1,2)  # 第一第二纬度转置 \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9e479dd-e96b-4f42-a9fb-ca001b4e36b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 2, 4])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(1, -1, 2, 4)  # 二者结果并不一致\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b70be4-6b82-4316-b5c2-376792053ff3",
   "metadata": {},
   "source": [
    "#### 实现clone函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c987505-08d8-4ca4-b2f3-fbdc9815a9e3",
   "metadata": {},
   "source": [
    "多头注意力需要用到多个结构相同的注意力模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb89aa82-2b18-4a07-b286-f779608f4b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch.nn import ModuleList\n",
    "\n",
    "def clones(module, N):\n",
    "    return ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712ee867-6546-40b8-a8ac-1ef0910aaba3",
   "metadata": {},
   "source": [
    "#### 实现多头注意力机制的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e541c6a3-e8ef-4693-87b7-0118be12bedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, head, embdding_dim, dropout = 0.1):\n",
    "        \"\"\"\n",
    "        head: 多头注意力的数量\n",
    "        embdding_dim: 输入的特征纬度\n",
    "        dropout: 置零的比率\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        \n",
    "        assert embdding_dim % head == 0  # 确认特征纬度能被head整除\n",
    "        \n",
    "        self.head = head\n",
    "        self.embdding_dim = embdding_dim\n",
    "        self.d_k = embdding_dim // head  # 每个head分别处理的特征纬度\n",
    "        # 生成结构中的线性层，共4个\n",
    "        self.linears = clones(nn.Linear(embdding_dim, embdding_dim), 4)  # 线性层输入输出都是特征的维数\n",
    "        self.attn = None  # 初始化注意力张量\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask = None):\n",
    "        \"\"\"query, key, value 是注意力的三个输入张量，mask代表掩码张量\"\"\"\n",
    "        if mask is not None: mask = mask.unsqueeze(1)  # 升维，代表多头中的第n个头\n",
    "        batch_size = query.size(0)  # 获得batchsize，即channel\n",
    "        \n",
    "        \"\"\"\n",
    "        未切割之前每个纬度的含义：0 batchsize 即一次性喂了多少个数据； \n",
    "        1 length 即该数据(句子的长度)； 2 dim 句子中每个元素的特征维度\n",
    "        model(x). 后面的处理：\n",
    "        1. 将输出张量的最后一个纬度进行切割，即划分输入给为多个head的特征,此时 2 nth 代表第n个头 3 dim 代表第n个头处理的特征维度\n",
    "        2. 进行transpose的操作 将 1 2 转置\n",
    "        \"\"\"\n",
    "        query, key, value = \\\n",
    "        [model(x).view(batch_size, -1, self.head, self.d_k).transpose(1, 2)   \n",
    "         for model, x in zip(self.linears, (query, key, value))]  # 分别对输入的Q K V进行全连接层的处理\n",
    "        \n",
    "        # 将每个头的输出传入到注意力层\n",
    "        x, self.attn = attention(query, key, value, mask = mask, dropout = self.dropout)\n",
    "        \n",
    "        # 得到每个头的计算结果是4维张量，需要进行形状的转换\n",
    "        # 前面已经将1，2两个维度进行过转置，在这里要重新转置回来\n",
    "        # 经历了transpose方法后，必须要使用contiguous方法，不然无法使用view\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.embdding_dim)\n",
    "        \n",
    "        # 最后对输出进行全连接\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89332746-df0b-4a2f-8d6f-d8fba632acac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin: tensor([[1, 2, 3],\n",
      "        [1, 5, 7]]) torch.Size([2, 3])\n",
      "emb: tensor([[[ 3.8845, -1.4806, -3.4664, -1.3254, -0.2796,  0.8907],\n",
      "         [ 1.5759, -1.3199,  1.3154,  1.3322, -3.8599,  2.9264],\n",
      "         [-2.0447,  0.2596,  0.1811, -3.0931, -0.3690,  0.4002]],\n",
      "\n",
      "        [[ 3.8845, -1.4806, -3.4664, -1.3254, -0.2796,  0.8907],\n",
      "         [ 0.1021, -1.1432,  0.5417,  1.5325, -2.7589,  1.4150],\n",
      "         [ 0.6348, -1.7899, -1.8147, -1.1538,  5.7850,  0.0276]]],\n",
      "       grad_fn=<MulBackward0>) torch.Size([2, 3, 6])\n",
      "pe: tensor([[[ 4.8556, -0.6007, -4.3330, -0.4068, -0.3495,  2.3634],\n",
      "         [ 3.0217, -0.0000,  1.7023,  0.0000, -0.0000,  0.0000],\n",
      "         [-1.4192, -0.1957,  0.3422, -2.6217, -0.4558,  1.7502]],\n",
      "\n",
      "        [[ 4.8556, -0.6007, -0.0000, -0.4068, -0.3495,  2.3634],\n",
      "         [ 1.1794, -0.7536,  0.7351,  3.1643, -3.4459,  3.0187],\n",
      "         [ 1.9302, -2.7575, -2.1525, -0.1977,  7.2366,  1.2845]]],\n",
      "       grad_fn=<MulBackward0>) torch.Size([2, 3, 6])\n",
      "mhax: tensor([[[-0.2177, -0.0312, -1.4992, -0.4413,  0.1909,  0.5597],\n",
      "         [-0.3107, -0.1547, -1.6793, -0.6990, -0.0879,  0.7307],\n",
      "         [-0.5125, -0.0241, -1.9405, -0.6205, -0.0614,  1.0085]],\n",
      "\n",
      "        [[ 0.2468, -0.0195, -0.6754, -0.4626,  0.0859,  0.2435],\n",
      "         [ 0.1762, -0.3300, -0.7826, -0.4348,  0.2417,  0.2743],\n",
      "         [ 0.3406, -0.5324, -0.5730, -0.6346,  0.0149,  0.3055]]],\n",
      "       grad_fn=<ViewBackward0>) torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "d_model = 6  # 要是 2 的倍数\n",
    "vocab = 10\n",
    "dropout = 0.2\n",
    "maxlen = 20\n",
    "head = 3\n",
    "x = Variable(torch.LongTensor([[1,2,3], [1,5,7]]))\n",
    "emb = Embeddings(d_model, vocab)\n",
    "embx = emb(x)\n",
    "pe = PositionalEncoding(d_model, dropout, maxlen)\n",
    "pex = pe(embx)\n",
    "print(\"origin:\", x, x.shape)\n",
    "print(\"emb:\", embx, embx.shape)\n",
    "print(\"pe:\", pex, pex.shape)\n",
    "query = key = value = pex  # 文本嵌入位置编码之后的输入\n",
    "mask = Variable(torch.zeros((2,3,3)))  # mask: batchsize * length * length\n",
    "\n",
    "mha = MultiHeadAttention(head = head, embdding_dim = d_model, dropout = dropout)\n",
    "mhax = mha(query, key, value, mask)\n",
    "print(\"mhax:\", mhax, mhax.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2ccdae-2af9-419f-b42b-d3c459007020",
   "metadata": {},
   "source": [
    "## 前馈全连接层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e53e2-23f1-4c46-bf07-fe33f690d5af",
   "metadata": {},
   "source": [
    "考虑到zhu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb24cae2-5732-4574-93c7-9566cbeeb671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout = 0.1):\n",
    "        \"\"\"\n",
    "        d_model: 词嵌入维度，特征维度\n",
    "        d_ff: 第一个线性层的输出，第二个线性层的输入\n",
    "        dropout: 置零比率\n",
    "        \"\"\"\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        \n",
    "        self.w1 = nn.Linear(d_model, d_ff)\n",
    "        self.w2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x 代表上一层的输出\n",
    "        \"\"\"\n",
    "        return self.w2(self.dropout(F.relu(self.w1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea615637-cdca-4119-8af5-29ed2414798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 6\n",
    "d_ff = 6\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33358978-4c5a-4105-bc66-b870fb798ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2637, -0.0758, -0.4798,  0.5895,  0.4317, -0.5520],\n",
      "         [-0.3093, -0.0863, -0.5154,  0.6792,  0.4811, -0.5909],\n",
      "         [-0.3156, -0.0957, -0.5451,  0.6866,  0.5001, -0.6437]],\n",
      "\n",
      "        [[-0.3063, -0.1257, -0.4345,  0.6693,  0.5353, -0.5732],\n",
      "         [-0.2572, -0.0733, -0.4717,  0.5774,  0.4232, -0.5406],\n",
      "         [-0.2948, -0.0777, -0.4875,  0.6540,  0.4573, -0.5468]]],\n",
      "       grad_fn=<ViewBackward0>) torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "x = mhax\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "ffx = ff(x)\n",
    "print(ffx, ffx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500d6dec-dfe8-4d6c-b3cb-b4d4df394b12",
   "metadata": {},
   "source": [
    "## 归一化层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207fdbd-3ed8-4250-a495-d5877c80cd77",
   "metadata": {},
   "source": [
    "使得网络的输出都维持在合理的范围之内，不会出现过大或过小的情况，方便训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80fa6fc9-9c83-449c-9906-9dc5419d09e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps = 1e-6):\n",
    "        \"\"\"\n",
    "        features: 词嵌入维度\n",
    "        eps: 一个足够小的正数，用来在规范化计算公式的分母中防止除零操作\n",
    "        \"\"\"\n",
    "        super(LayerNorm, self).__init__()\n",
    "        \n",
    "        # 初始化两个参数张量a2，b2 用于对结果做规范化计算\n",
    "        # 将其用nn.Parameter进行封装，代表他们是模型中的参数\n",
    "        self.a2 = nn.Parameter(torch.ones(features))\n",
    "        self.b2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim = True)  # 在最后一个维度即特征维求均值，保持维度\n",
    "        std = x.std(-1, keepdim = True)  # 同上\n",
    "        return self.a2 * (x - mean) / (std + self.eps) + self.b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "772c89a3-8013-489d-94f0-2d544d79caba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 6\n",
    "x = ffx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "53efc7f3-c497-4764-8063-1e5841c2ab9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.4332, -0.0367, -0.8891,  1.3666,  1.0337, -1.0413],\n",
      "         [-0.4785, -0.0557, -0.8691,  1.3955,  1.0200, -1.0122],\n",
      "         [-0.4485, -0.0487, -0.8656,  1.3733,  1.0342, -1.0448]],\n",
      "\n",
      "        [[-0.5137, -0.1665, -0.7601,  1.3624,  1.1046, -1.0268],\n",
      "         [-0.4309, -0.0350, -0.8925,  1.3655,  1.0337, -1.0408],\n",
      "         [-0.4908, -0.0568, -0.8759,  1.4055,  1.0123, -0.9943]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(features)\n",
    "lnx = ln(x)\n",
    "print(lnx, lnx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185dfdaa-60da-46c6-b879-2f1597d5e071",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 子层连接结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6acffe7-b464-41ac-bbca-7ac0d7772dcd",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=./imgs/res.png width=25% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9cea54-ca73-4577-8b7a-a25fe8d51e73",
   "metadata": {},
   "source": [
    "即子层函数加残差连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9996a7b-52e0-4c61-b121-a3e8688b1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubLayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout = 0.1):\n",
    "        \"\"\"size: 词嵌入维度 dropout: 置零比率\"\"\"\n",
    "        super(SubLayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.size = size\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        \"\"\"x: 上一层的输出 sublayer：该子层中的子层函数，如attention等\"\"\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))  # 将上一层输出经过归一化送入子层函数，再dropout以及残差连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4218bb2-18d1-4511-bfec-cfa436ebfc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 4.9678, -0.8298, -4.3330, -0.8675,  0.3727,  2.4276],\n",
      "         [ 3.1339, -0.2291,  1.7580, -0.4607,  0.7223,  0.0642],\n",
      "         [-1.2618, -0.4020,  0.3099, -2.9680, -0.4558,  1.7502]],\n",
      "\n",
      "        [[ 5.1224, -0.8391,  0.1135, -0.6318,  0.5595,  2.4885],\n",
      "         [ 1.5108, -0.9266,  0.7010,  3.1008, -2.6581,  3.1745],\n",
      "         [ 2.1970, -2.9959, -2.1525, -0.4227,  7.2366,  1.2845]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "size = d_model = 6  # 特征维度 6\n",
    "head = 3  # 3 个头\n",
    "dropout = 0.2\n",
    "\n",
    "x = pex  # 位置编码后的输出\n",
    "mask = Variable(torch.zeros(2, 3, 3))  # batchsize 2 length 3\n",
    "self_attn = MultiHeadAttention(head, d_model)  # 多头自注意力\n",
    "\n",
    "sublayer = lambda x: self_attn(x, x, x, mask) \n",
    "\n",
    "sc = SubLayerConnection(size, dropout)\n",
    "scx = sc(x, sublayer)\n",
    "print(scx, scx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345c742-fd11-4642-a5c8-4537779b760b",
   "metadata": {},
   "source": [
    "## 编码器层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e301e521-e922-46db-bdd9-a57e2a0a5194",
   "metadata": {},
   "source": [
    "作为编码器的组成单元，每个编码器层完成一次对输入的特征提取，即编码过程。多个编码器层组成编码器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea37e5-f845-45c6-b79c-b4a4ff07735e",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=./imgs/res.png width=25% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd8ae181-a661-445c-9243-13161e4b708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        \"\"\"\n",
    "        size: 词嵌入维度\n",
    "        self_attn: 多头注意力子层的实例化对象\n",
    "        feed_forward: 前馈全连接层的实例化对象\n",
    "        dropout: 置零比率\n",
    "        \"\"\"\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SubLayerConnection(size, dropout), 2)  # 复制两个子层结构\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))  # 第一个自注意力层\n",
    "        return self.sublayer[1](x, self.feed_forward)  # 第二个前馈全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77bd6a40-9bac-42a2-8da0-27c1344e1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = d_model = 6  # 词嵌入维度\n",
    "head = 3  # 头数量\n",
    "d_ff = 3  # 全连接层维度\n",
    "x = pex\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd618411-1ed0-48be-847a-effec4f4e6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.0561, -0.5475, -4.2266, -1.0762, -0.7733,  2.2734],\n",
      "         [ 3.0217, -0.0528,  1.7953, -0.7089,  0.2792,  0.1649],\n",
      "         [-0.7983, -0.3059,  0.3841, -3.4623, -0.4840,  1.4067]],\n",
      "\n",
      "        [[ 5.4026, -0.5363,  0.5002, -1.2378, -1.2746,  2.6544],\n",
      "         [ 1.5407, -0.7895,  0.8690,  2.2927, -3.0183,  3.4550],\n",
      "         [ 2.6608, -2.4170, -1.8692, -0.7672,  7.1582,  1.5987]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "self_attn = MultiHeadAttention(head, d_model)\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "mask = Variable(torch.ones(2, 3, 3))\n",
    "\n",
    "el = EncoderLayer(size, self_attn, ff, dropout)\n",
    "elx = el(x, mask)\n",
    "print(elx, elx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95fa2f0-14ab-46c6-888a-8ca4b0aa997b",
   "metadata": {},
   "source": [
    "## 编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe463124-3de9-4f6b-a4b0-de7fb3f5f727",
   "metadata": {},
   "source": [
    "编码器用于对输入进行指定的特征提取过程，由N个编码器层堆叠而成。  \n",
    "编码器类的输出就是Transformer中编码器的特征提取表示，它将成为编码器的输出的一部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0929b16-cd3a-4787-ab83-6a0a7109baf4",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=./imgs/encoder-layer.png width=30% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a0c15f8-8495-4332-a31c-97e573738435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        \"\"\"layer: 代表解码器层 N:代表解码器中有几个layer\"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)  # 复制 N 个编码器层\n",
    "        self.norm = LayerNorm(layer.size)  # 初始化一个规范化层，作用在编码器的最后面\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"x: 上一层输出张量， mask：掩码张量\"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69fd2a1d-29c5-4761-a1c1-7a7047d82d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = d_model = 6\n",
    "d_ff = 3\n",
    "head = 3\n",
    "dropout = 0.2\n",
    "N = 6\n",
    "c = copy.deepcopy\n",
    "attn = MultiHeadAttention(head, d_model)\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "layer = EncoderLayer(size, c(attn), c(ff), dropout)\n",
    "mask = Variable(torch.zeros(2, 3, 3))\n",
    "x = pex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5881d216-4fc8-4a77-8d13-b989dd5f14b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.3469, -0.0511, -1.2224, -0.8977, -0.1091,  0.9335],\n",
      "         [ 0.7794,  0.5000, -0.3535, -1.6574, -0.3424,  1.0739],\n",
      "         [-0.6509,  0.4056, -0.3593, -1.3701,  0.5097,  1.4649]],\n",
      "\n",
      "        [[ 1.4468,  0.3115, -0.5582, -1.2771, -0.6188,  0.6958],\n",
      "         [ 0.3410,  0.3520, -1.1145, -0.3353, -0.8704,  1.6272],\n",
      "         [ 1.1492, -0.3128, -1.0484, -1.2043,  0.8290,  0.5873]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "en = Encoder(layer, N)\n",
    "enx = en(x, mask)\n",
    "print(enx, enx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33218f3-e31b-44a7-88db-76ed7ba1d764",
   "metadata": {},
   "source": [
    "# 解码器部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f0c7a-3bea-491d-b389-e56f0d3e0f8f",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=./imgs/decoder.png width=30% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d375c3f9-e770-40fb-b9a2-9b650e63f9a4",
   "metadata": {},
   "source": [
    "## 解码器层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bb410b-ca9b-4b1c-a1aa-22a48a9fe7ad",
   "metadata": {},
   "source": [
    "作为解码器的组成单元，每个解码器层根据给定的输入向目标方向进行特征提取操作，即解码过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f5090b7-1f29-4fed-9ef6-62f29d582895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        \"\"\"\n",
    "        size: 词嵌入维度\n",
    "        self_attn: 多头自注意力机制对象\n",
    "        src_attn: 常规注意力机制对象\n",
    "        feed_forward: 前馈全连接层\n",
    "        dropout: 置零比率\n",
    "        \"\"\"\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.dropout = dropout\n",
    "        self.sublayer = clones(SubLayerConnection(size, dropout), 3)  # 复制 3 个子层连接对象\n",
    "    \n",
    "    def forward(self, x, memory, source_mask, target_mask):\n",
    "        \"\"\"\n",
    "        x: 上一层的输出\n",
    "        memory：编码器得到的句子的语义\n",
    "        source_mask: 源数据的掩码张量 -> 为了遮盖住对结果信息无用的数据\n",
    "        target_mask: 解码时遮盖住未来的信息，不产生因果问题\n",
    "        \"\"\"\n",
    "        m = memory\n",
    "        # 对输入进行自注意力操作，同时用掩码遮盖\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, target_mask))  \n",
    "        # 对输入进行常规注意力操作，遮盖住不重要的区域\n",
    "        # 形象理解即此处使用编码层获得的语义信息对目标的文本进行语义的提取处理\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, source_mask))\n",
    "        # 全连接层\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3dd8f1c-9d69-45c2-8ef5-8384dc000065",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = d_model = 6\n",
    "head = 3\n",
    "d_ff = 3  # 全连接层中间维度\n",
    "dropout = 0.2\n",
    "self_attn = src_attn = MultiHeadAttention(head, d_model, dropout)\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "x = pex  # 位置编码的 x\n",
    "memory = enx  # 编码层输出的 x\n",
    "mask = Variable(torch.zeros(2,3,3))\n",
    "source_mask = target_mask = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9b1493ad-54a4-415f-8358-5da360d44bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 6.6282,  0.2504, -4.2016, -1.3818,  0.3407,  1.8044],\n",
      "         [ 4.5422,  0.9363,  2.4530, -0.7655,  0.9313, -0.2787],\n",
      "         [-0.6684,  0.4788,  0.3806, -3.8594,  0.5337,  1.3313]],\n",
      "\n",
      "        [[ 5.5136, -0.1112,  0.7617, -1.5233,  0.5750,  1.5778],\n",
      "         [ 1.7645,  0.1676,  1.3989,  2.2690, -2.7667,  2.3048],\n",
      "         [ 2.8819, -2.0632, -1.3684, -0.7084,  8.0000,  1.7142]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "dl = DecoderLayer(size, self_attn, src_attn, feed_forward = ff, dropout = dropout)\n",
    "dlx = dl(x, memory, source_mask, target_mask)\n",
    "print(dlx, dlx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25936ee0-1862-4489-82d0-92c1b63f967a",
   "metadata": {},
   "source": [
    "## 解码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0bcc60-774f-4ceb-9492-cf35861c3efb",
   "metadata": {},
   "source": [
    "根据编码器的结果以及上一次预测的结果，对下一次可能出现的值进行表征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "49acbe66-d772-4462-80da-88a0690106c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        \"\"\"layer: 解码器层的对象； N：堆叠层数\"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)  # 即特征维度\n",
    "    \n",
    "    def forward(self, x, memory, source_mask, target_mask):\n",
    "        \"\"\"\n",
    "        x: 上一层输出\n",
    "        memory: 编码器的输出，即语义提取张量\n",
    "        source_mask: 源数据的掩码张量\n",
    "        target_mask: 目标数据的掩码张量\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, source_mask, target_mask)\n",
    "        return self.norm(x)  # 输出归一化的 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15bb9d93-77cd-42ce-84a7-8f5dbf7161bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = d_model = 6\n",
    "head = 3\n",
    "d_ff = 3  # 全连接层中间维度\n",
    "dropout = 0.2\n",
    "N = 6\n",
    "self_attn = src_attn = MultiHeadAttention(head, d_model, dropout)\n",
    "ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "x = pex  # 位置编码的 x\n",
    "memory = enx  # 编码层输出的 x\n",
    "mask = Variable(torch.zeros(2,3,3))\n",
    "source_mask = target_mask = mask\n",
    "dl = DecoderLayer(size, self_attn, src_attn, feed_forward = ff, dropout = dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4276fa94-deaf-462c-98d4-f298790ecf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9365, -0.4618, -0.4322, -1.5576,  0.4847,  1.0304],\n",
      "         [ 1.1654,  0.2689,  0.3806, -1.8065, -0.2880,  0.2795],\n",
      "         [-0.0305,  0.1631,  0.8662, -1.8461, -0.0535,  0.9006]],\n",
      "\n",
      "        [[ 1.4039, -0.1870, -0.0595, -1.6784,  0.1230,  0.3981],\n",
      "         [-0.2392, -0.3472,  0.4160, -1.2336, -0.3330,  1.7369],\n",
      "         [ 0.5674, -1.0952,  0.1276, -1.2342,  1.3665,  0.2679]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "de = Decoder(layer = dl, N = N)\n",
    "dex = de(x, memory, source_mask, target_mask)\n",
    "print(dex, dex.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2fb53-9a16-438f-a50e-ebf614d4da0b",
   "metadata": {},
   "source": [
    "# 输出部分实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2238d3cc-e7a1-4a41-8e03-0263a3cfbef2",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=./imgs/output.png width=25% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f9119-b175-4659-8110-27c12c6778a1",
   "metadata": {},
   "source": [
    "- 线性层：通过对上一步的线性变化得到指定维度的输出，也就是转换为度的作用。\n",
    "- softmax层：使最后一维的向量中的数字缩放到 0 - 1 的概率值域内，并满足它们的和为 1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "922d5061-a834-4010-a1a4-692a984d258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16aca0bb-b0ee-4a14-b1ac-706a0519e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将线性层和softmax计算层一起实现，因为二者的共同目标是生成最后的结构\n",
    "# 因此把类的名字叫做Generator， 生成器类\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        \"\"\"d_model: 词嵌入维度；vocab_size: 词表大小\"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        self.project = nn.Linear(d_model, vocab_size)  # 映射到指定维度\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"x: 上一层的输出张量\"\"\"\n",
    "        # return F.softmax(self.project(x), dim = -1)  # 在最后一个维度进行映射操作即特征映射\n",
    "        return F.log_softmax(self.project(x), dim = -1)  # 另一种softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26e6ec53-0f98-4cb3-8382-075a66153bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 6\n",
    "vocab_size = 10\n",
    "x = dex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cacb1645-c55b-471b-a8a7-2c73c4ee5c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.3013, -2.1341, -2.7590, -1.7552, -3.4373, -2.7430, -2.5643,\n",
      "          -1.9503, -2.7872, -1.7840],\n",
      "         [-2.1983, -1.2795, -3.3211, -2.1018, -3.1781, -3.0560, -2.5728,\n",
      "          -2.3910, -2.7137, -2.0434],\n",
      "         [-2.7156, -1.4871, -2.4989, -2.4766, -2.8369, -2.5102, -2.6038,\n",
      "          -2.1814, -2.3710, -2.1079]],\n",
      "\n",
      "        [[-2.1210, -1.5872, -3.2404, -1.7843, -3.4087, -3.0195, -2.5256,\n",
      "          -2.3069, -2.7902, -1.9267],\n",
      "         [-2.9621, -2.2435, -2.0339, -2.4450, -2.9178, -2.0346, -2.5325,\n",
      "          -2.0221, -2.7543, -1.8056],\n",
      "         [-2.4831, -1.9012, -2.4460, -1.7923, -3.2660, -2.3698, -2.4966,\n",
      "          -2.5117, -2.1690, -2.2588]]], grad_fn=<LogSoftmaxBackward0>) torch.Size([2, 3, 10])\n"
     ]
    }
   ],
   "source": [
    "gen = Generator(d_model, vocab_size)\n",
    "genx = gen(x)\n",
    "print(genx, genx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab00216-349a-4f03-bd2e-4f8923a577f9",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb2d348-3e66-4fb6-85b6-4174d9a44e55",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=./imgs/transformer.png width=30% />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2eb76aa7-ab9c-44af-8963-2be89fad78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder, source_embed, target_embed, generator):\n",
    "        \"\"\"\n",
    "        encoder: 编码器对象\n",
    "        decoder: 解码器对象\n",
    "        source_embed: 源数据的嵌入函数\n",
    "        target_embed:目标数据的嵌入函数\n",
    "        generator: 输出部分类别生成器对象\n",
    "        \"\"\"\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = source_embed\n",
    "        self.tgt_embed = target_embed\n",
    "        self.generator = generator\n",
    "    \n",
    "    def forward(self, source, target, source_mask, target_mask):\n",
    "        \"\"\"\n",
    "        source: 代表源数据\n",
    "        target: 代表目标数据\n",
    "        source_mask: 代表源数据的掩码张量\n",
    "        target_mask: 代表目标数据的掩码张量\n",
    "        \"\"\"\n",
    "        return self.decode(\n",
    "            self.encode(source, source_mask),\n",
    "            source_mask,\n",
    "            target,\n",
    "            target_mask\n",
    "        )\n",
    "    \n",
    "    def encode(self, source, source_mask):\n",
    "        # 对源输入进行词嵌入并带着 mask 进行 encode\n",
    "        return self.encoder(self.src_embed(source), source_mask)\n",
    "    \n",
    "    def decode(self, memory, source_mask, target, target_mask):\n",
    "        # 对目标的输出进行词嵌入，并且同编码器的输出一同进行解码\n",
    "        return self.decoder(self.tgt_embed(target), memory, source_mask, target_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "155a639f-a154-4569-af3c-e04e273f8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10\n",
    "d_model = 6\n",
    "encoder = en\n",
    "decoder = de\n",
    "source_embed = nn.Embedding(vocab_size, d_model)\n",
    "target_embed = nn.Embedding(vocab_size, d_model)  # 演示用只进行嵌入没进行位置编码\n",
    "gen = gen\n",
    "source = target = Variable(torch.LongTensor([[1,2,3], [1,3,5]]))\n",
    "source_mask = target_mask = Variable(torch.zeros(2,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08cf29a8-bf0e-42e3-a6fb-d6ea919b1fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5984, -0.1317,  0.7504, -1.5379,  0.2369,  1.2807],\n",
      "         [ 0.2171, -0.4994,  0.5030, -1.7928,  0.7719,  0.8002],\n",
      "         [-0.1979, -0.3047,  0.3110, -1.7074,  1.1127,  0.7862]],\n",
      "\n",
      "        [[-0.1407, -0.0658,  0.8100, -1.8114,  0.2107,  0.9971],\n",
      "         [-0.0019, -0.5077,  0.6756, -1.6698,  0.3236,  1.1802],\n",
      "         [-0.0862, -0.0998,  0.9731, -1.8428,  0.7308,  0.3248]]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "ed = EncoderDecoder(encoder, decoder, source_embed, target_embed, gen)\n",
    "edx = ed(source, target, source_mask, target_mask)\n",
    "print(edx, edx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560afcd-b5cb-42de-91ea-7ee772db17e9",
   "metadata": {},
   "source": [
    "## make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29d141b3-650b-480f-bbfc-9227d70cdd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(source_vocab, target_vocab, N = 6, d_model = 512, d_ff = 1024, head = 8, dropout = 0.2):\n",
    "    \"\"\"\n",
    "    source_vocab: 代表源数据的词汇总数\n",
    "    target_vocab: 代表目标数据的词汇总数\n",
    "    N: 代表编码器和解码器堆叠的层数\n",
    "    d_model: 代表词嵌入的维度\n",
    "    d_ff: 代表前馈全连接层中变换矩阵的维度\n",
    "    head: 多头注意力机制中的头数\n",
    "    dropout: 置零的比率\n",
    "    \"\"\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadAttention(head, d_model)  # 实例化多头注意力的对象\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff)  # 实例化全连接层对象\n",
    "    pe = PositionalEncoding(d_model, dropout)  # 实例化位置编码器\n",
    "    \n",
    "    # 实例化模型 model，利用EncoderDecoder类\n",
    "    # 编码器的结构中有 2 个子层，attention层和全连接层\n",
    "    # 解码器中有 3 个子层，两个attention和一个全连接层\n",
    "    # 都各自堆叠 N 次\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(\n",
    "            EncoderLayer(\n",
    "                d_model,  # 词嵌入维度\n",
    "                c(attn),  # 自注意力层  \n",
    "                c(ff),   # 全连接层\n",
    "                dropout\n",
    "            ), N),  # 堆叠 N 层\n",
    "        Decoder(\n",
    "            DecoderLayer(\n",
    "                d_model,\n",
    "                c(attn),  \n",
    "                c(attn),  # 这里的两个注意力对象不同，功能也不同\n",
    "                c(ff),\n",
    "                dropout\n",
    "            ), N),  # 堆叠 N 层\n",
    "        nn.Sequential(Embeddings(d_model, source_vocab), c(pe)),  # 输入文本的嵌入，加入位置编码\n",
    "        nn.Sequential(Embeddings(d_model, target_vocab), c(pe)),  # 对目标文本进行词嵌入\n",
    "        Generator(d_model, target_vocab)  # 由特征向量映射到目标词汇表\n",
    "    )\n",
    "    \n",
    "    # 初始化模型参数\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1: nn.init.xavier_uniform_(p)  # 进行均匀初始化\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "541a2def-0394-417b-b5e3-4f8bedce7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_vocab = target_vocab = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "121cc6d4-5442-4d0e-95cf-5c5e88ce3b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (w2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SubLayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): SubLayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "          (w2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SubLayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (1): SubLayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (2): SubLayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(10, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(10, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (project): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_model(source_vocab, target_vocab, N = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8b65b5-74c5-4b9a-baf4-cd71446a22c2",
   "metadata": {},
   "source": [
    "# 模型测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f4df8d-c69b-485d-9576-76b8ef498e9d",
   "metadata": {},
   "source": [
    "> copy 任务：\n",
    "> - 任务描述：针对数字序列进行学习，学习的最终目标是使得输出与输入的序列相同，如输入[1,2,3]，也输出[1,2,3]。\n",
    "> - 任务意义：copy任务在模型基础测试中具有重要意义，因为copy操作对于模型来讲是一条明显规律，因此模型能否在短时间内，小数据集中学会它，可以帮助我们判定模型所有过程是否正常，是否已经具备基本学习能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f524a-48cc-4a0d-91c2-9d7846f8ee27",
   "metadata": {},
   "source": [
    "> 使用copy任务进行模型基本测试的四步曲：\n",
    "> 1. 构建数据集生成器\n",
    "> 2. 获得Transformer模型及其优化器和损失函数\n",
    "> 3. 运行模型进行训练和评估\n",
    "> 4. 使用模型进行贪婪解码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5460216-477c-4b75-bf44-01d50aa1d086",
   "metadata": {},
   "source": [
    "## 数据集生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e31d0173-1e31-4520-b647-eb9557ef1827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyitcast.transformer_utils import Batch, get_std_opt, LabelSmoothing, SimpleLossCompute, run_epoch, greedy_decode\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8b57d69-c6fa-49c5-8fbd-6fad657a229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(V, batch_size, batch_num):\n",
    "    \"\"\"\n",
    "    V: 随即生成数据的上界 + 1\n",
    "    batch_size: 一次喂给网络多少个数据样本\n",
    "    batch_num: 一共喂多少次\n",
    "    \"\"\"\n",
    "    for i in range(batch_num):\n",
    "        data = torch.from_numpy(np.random.randint(1, V, size = (batch_size, 10), dtype = \"int64\"))  # 每一条数据里包含 10 个数\n",
    "        data[:, 0] = 1  # 将数据的第一列全部设置为 1 ，作为起始标志\n",
    "        source = Variable(data, requires_grad = False)\n",
    "        target = Variable(data, requires_grad = False)  # 源数据与目标数据一致并且不随着梯度更新而改变\n",
    "        \n",
    "        yield Batch(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c54171f6-553e-462e-867a-075c28881bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 10\n",
    "batch_size = 2\n",
    "batch_num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9ce16974-50e0-4537-b369-bb2a067b8cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 3, 4, 7, 4, 7, 6, 6, 3, 5],\n",
      "        [1, 1, 2, 3, 1, 6, 3, 9, 8, 5]])\n",
      "tensor([[1, 8, 8, 2, 4, 5, 3, 2, 8, 3],\n",
      "        [1, 3, 2, 9, 3, 5, 6, 8, 2, 9]])\n"
     ]
    }
   ],
   "source": [
    "data = data_generator(V, batch_size, batch_num)\n",
    "for d in data:\n",
    "    print(d.src)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a09e9f8-82bc-43a7-930d-cdad83fa55f9",
   "metadata": {},
   "source": [
    "## 优化器及损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5967a02-1528-4dfb-9962-21736544a625",
   "metadata": {},
   "source": [
    "label smoothing 对标签进行平滑  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a91a005-ec22-4ecd-a619-4c3ad907359b",
   "metadata": {},
   "source": [
    "第一个参数 size 代表目标数据的词汇总数，也就是最后一层得到的张量最后一维的大小。  \n",
    "第二个参数 padding_idx 表示要将哪些数字替换成 0 ，一般此项为 0 表示不进行替换。  \n",
    "第三个参数 smoothing 表示标签的平滑程度，如标签为 1 则平滑后的值变为 [1 - smoothing, 1 + smoothing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2fc88173-adc6-478d-9a68-32cb3102c78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\envs\\TFO\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-3.1182)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "crit = LabelSmoothing(size = 5, padding_idx = 0, smoothing = 0.5)\n",
    "predict = Variable(torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0], [0, 0.2, 0.7, 0.1, 0], [0, 0.2, 0.7, 0.1, 0]]))\n",
    "target = Variable(torch.LongTensor([2, 1, 0]))\n",
    "crit(predict, target)\n",
    "# plt.imshow(crit.true_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b4dc12b7-7eae-40f6-ba0f-7f3a1340a045",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(V, V, N = 2)  # 获得模型的实例化对象\n",
    "model_optimizer = get_std_opt(model)  # 获得模型的优化器\n",
    "criterion = LabelSmoothing(size = V, padding_idx = 0, smoothing = 0.0)  # 获得标签平滑对象\n",
    "loss = SimpleLossCompute(model.generator, criterion, model_optimizer)  # 获得利用标签平滑的结果得到的损失计算方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c952cb9-84a0-4fa1-b3ed-229810854014",
   "metadata": {},
   "source": [
    "## 运行及评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "37a151f8-92f4-413e-83fe-3449b5f50a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, loss, epochs = 10):\n",
    "    \"\"\"\n",
    "    model: 要训练的模型\n",
    "    loss: 使用的损失计算方法\n",
    "    epochs: 模型训练的轮次\n",
    "    \"\"\"\n",
    "    for _ in range(epochs):\n",
    "        model.train()  # 训练模式，参数更新\n",
    "        run_epoch(data_generator(V, 8, 20), model, loss)  \n",
    "        \n",
    "        model.eval()  # 评估模式，参数保留\n",
    "        run_epoch(data_generator(V, 8, 5), model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "edefa5b3-b183-4d63-907e-785a3552b254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 2.998564 Tokens per Sec: 573.702637\n",
      "Epoch Step: 1 Loss: 2.735607 Tokens per Sec: 620.688049\n",
      "Epoch Step: 1 Loss: 2.611072 Tokens per Sec: 618.025635\n",
      "Epoch Step: 1 Loss: 2.237946 Tokens per Sec: 657.596252\n",
      "Epoch Step: 1 Loss: 2.235550 Tokens per Sec: 607.594971\n",
      "Epoch Step: 1 Loss: 1.853113 Tokens per Sec: 648.644836\n",
      "Epoch Step: 1 Loss: 2.240161 Tokens per Sec: 620.688049\n",
      "Epoch Step: 1 Loss: 1.720811 Tokens per Sec: 631.581787\n",
      "Epoch Step: 1 Loss: 1.951455 Tokens per Sec: 623.377441\n",
      "Epoch Step: 1 Loss: 1.598292 Tokens per Sec: 648.652466\n",
      "Epoch Step: 1 Loss: 2.019941 Tokens per Sec: 620.681702\n",
      "Epoch Step: 1 Loss: 1.514075 Tokens per Sec: 654.540405\n",
      "Epoch Step: 1 Loss: 1.776644 Tokens per Sec: 620.737854\n",
      "Epoch Step: 1 Loss: 1.529034 Tokens per Sec: 651.583862\n",
      "Epoch Step: 1 Loss: 1.810929 Tokens per Sec: 626.089478\n",
      "Epoch Step: 1 Loss: 1.553615 Tokens per Sec: 651.583862\n",
      "Epoch Step: 1 Loss: 1.843961 Tokens per Sec: 634.356567\n",
      "Epoch Step: 1 Loss: 1.433536 Tokens per Sec: 657.531799\n",
      "Epoch Step: 1 Loss: 1.786264 Tokens per Sec: 615.385925\n",
      "Epoch Step: 1 Loss: 1.410948 Tokens per Sec: 654.546814\n"
     ]
    }
   ],
   "source": [
    "run(model, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5748f8c-95fc-491b-9817-b8a3969ab715",
   "metadata": {},
   "source": [
    "## 使用模型进行贪婪解码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59211acc-ffca-44e9-84b2-87200e35718e",
   "metadata": {},
   "source": [
    "> 导入greddy_decode, 该工具将对最终结果进行贪婪解码， 贪婪解码的方式是每次预测都选择概率最大的结果作为输出，它不一定能获得全局最优解，但却具有最高的执行效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "57729c6c-d55e-4354-b4e3-2656bd57ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 11\n",
    "model = make_model(V, V, N = 2)\n",
    "model_optimizer = get_std_opt(model)  # 获得模型的优化器\n",
    "criterion = LabelSmoothing(size = V, padding_idx = 0, smoothing = 0.0)  # 获得标签平滑对象\n",
    "loss = SimpleLossCompute(model.generator, criterion, model_optimizer)  # 获得利用标签平滑的结果得到的损失计算方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "464c1a73-eff8-4105-8d97-4b7a1ca1336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, loss, epochs = 10):\n",
    "    \"\"\"\n",
    "    model: 要训练的模型\n",
    "    loss: 使用的损失计算方法\n",
    "    epochs: 模型训练的轮次\n",
    "    \"\"\"\n",
    "    for _ in range(epochs):\n",
    "        model.train()  # 训练模式，参数更新\n",
    "        run_epoch(data_generator(V, 8, 20), model, loss)  \n",
    "        \n",
    "        model.eval()  # 评估模式，参数保留\n",
    "        run_epoch(data_generator(V, 8, 5), model, loss)\n",
    "    \n",
    "    model.eval()\n",
    "    source = Variable(torch.LongTensor([[1,2,4,3,5,7,6,8,9,10]]))\n",
    "    source_mask = Variable(torch.ones(1, 1, 10))  # 全 1 的掩码张量，无任何遮掩\n",
    "    result = greedy_decode(model, source, source_mask, max_len = 10, start_symbol = 1)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c2a03522-013c-471d-a79d-fb6cac8b0ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Step: 1 Loss: 3.409424 Tokens per Sec: 564.709351\n",
      "Epoch Step: 1 Loss: 2.483949 Tokens per Sec: 654.551758\n",
      "Epoch Step: 1 Loss: 2.884865 Tokens per Sec: 597.511719\n",
      "Epoch Step: 1 Loss: 2.422046 Tokens per Sec: 637.167969\n",
      "Epoch Step: 1 Loss: 2.501607 Tokens per Sec: 585.367981\n",
      "Epoch Step: 1 Loss: 2.121666 Tokens per Sec: 631.579163\n",
      "Epoch Step: 1 Loss: 2.299432 Tokens per Sec: 620.686829\n",
      "Epoch Step: 1 Loss: 1.949369 Tokens per Sec: 637.165283\n",
      "Epoch Step: 1 Loss: 2.006244 Tokens per Sec: 623.372253\n",
      "Epoch Step: 1 Loss: 1.832286 Tokens per Sec: 645.742554\n",
      "Epoch Step: 1 Loss: 2.045516 Tokens per Sec: 620.698303\n",
      "Epoch Step: 1 Loss: 1.619347 Tokens per Sec: 648.653198\n",
      "Epoch Step: 1 Loss: 1.841399 Tokens per Sec: 620.691895\n",
      "Epoch Step: 1 Loss: 1.619378 Tokens per Sec: 648.646179\n",
      "Epoch Step: 1 Loss: 1.840465 Tokens per Sec: 618.025635\n",
      "Epoch Step: 1 Loss: 1.614929 Tokens per Sec: 657.533203\n",
      "Epoch Step: 1 Loss: 1.886616 Tokens per Sec: 612.763123\n",
      "Epoch Step: 1 Loss: 1.483351 Tokens per Sec: 651.581055\n",
      "Epoch Step: 1 Loss: 1.668508 Tokens per Sec: 607.594971\n",
      "Epoch Step: 1 Loss: 1.385840 Tokens per Sec: 642.916077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4, 3, 5, 2, 7, 6, 8, 9, 7]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(model, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a530e876-fabc-40dc-8865-7c6120f4f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4bd5708-0cb3-431e-8608-2b5a4b41dccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((2, 3, 6))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad88f484-a635-469d-a899-2e1b37c333d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 6, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.transpose(0, 2, 1)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "205c1b6c-aac8-491b-8ad0-5c82e9660471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.matmul(a, b)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a25ec88f-16f9-494f-afc3-d7721d8d5e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.matmul(c, a)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c541db7f-6564-4ac4-adc7-74bf31461a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0752603-bf71-4e38-b0f5-b40184c7a22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd7ef3d-3b20-4914-b7f5-da5442291226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa747d-0bea-4a04-9b03-bcfb017bcddc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f212e-cfa3-42f9-bd86-9c994f7be3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305ca7c3-5add-4a55-b0ef-ac9d471620ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9850d780-2d88-4415-8e0b-93c0187d3549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d798b-123c-43a1-8a41-733ec2bf9992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2ee03-4b18-4853-add0-fa2ad1f363a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17753057-55f7-4284-8c9b-0893c1a79750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff15256-5b53-4b71-bafe-afbb77815509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784d89b-efb6-4bf2-984c-52ab272ac4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bfbdc5-0acd-4aa1-a61b-ab78dd2f1224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f1fa3-db3c-4fbe-92ab-4cc7d8c89293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e505e46-e6cb-4998-a08f-e1d2c0b20110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f0414-d2e4-4e76-8e01-2bbefad8bbf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932dee77-f538-44a7-991d-b583be6d1c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c61d6-dd22-40f1-bae0-79673fb38ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723affb-2da7-4751-81fc-46293c41e7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3418462-41b2-437f-a72c-f303a2c169a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
